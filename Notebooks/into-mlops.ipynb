{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# A SIMPLIFIED MLOPS GUIDE USING MLFLOW",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "MLOps is one of the crucial phase in a machine learning lifecycle to keep machine learning models maintained and perform well. There's an open source MLOps tool that easily to use, comprehensive ML library, and manage end-to-end ML workkflows from development to production. It is called [MLflow](https://mlflow.org). Here's how to understand by doing a fundamental implementation using ML flow. Let's just dive into the notebook.\n",
    "\n",
    "[SOURCE](https://mlflow.org/docs/latest/getting-started/logging-first-model/index.html)"
   ],
   "id": "e45425beb9736fa9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Install MLflow (Including libraries and dependencies)\n",
    "\n",
    "run it on your IDE terminal\n",
    "\n",
    "`pip install mlflow`"
   ],
   "id": "9320760205345a18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Launch the Mlflow Tracking Server\n",
    "\n",
    "Run it on your IDE terminal\n",
    "\n",
    "`mlflow server --host 127.0.0.1 --port 8080`\n",
    "\n",
    "You need to launch the MLflow tracking server and always keep it ongoing during the tutorial, if you close/kill the terminal it'll shut down the server. The screen should be showing like [this](../MLOps/Screenshots/ss1.png) (or ss1.png in the Screenshots folder)"
   ],
   "id": "6197cf8c27733aa6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Using the MLFflow Client API using `MLflowClient`\n",
    "it could use for :\n",
    "1. Initiate a new Experiment.\n",
    "2. Start Runs within an Experiment.\n",
    "3. Document parameters, metrics, and tags for your Runs.\n",
    "4. Log artifacts linked to runs, such as models, tables, plots, and more.\n",
    "\n"
   ],
   "id": "2d6a5948d574d090"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 Import Dependencies",
   "id": "898adaf4e155a356"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:47:40.038045Z",
     "start_time": "2025-01-16T03:47:38.521640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlflow import MlflowClient\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "id": "7df9140457caed5e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Configuring the MLflow Tracking Client",
   "id": "5f4661a9f59b273b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:47:40.050701Z",
     "start_time": "2025-01-16T03:47:40.047586Z"
    }
   },
   "cell_type": "code",
   "source": "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")",
   "id": "c2f116385d60a97a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Default Experiment\n",
    "It's an outset of starting MLflow Tracking Server that if you don‚Äôt explicitly create a new experiment in MLflow, any run data is automatically stored in the ‚ÄúDefault Experiment‚Äù so that it isn‚Äôt lost."
   ],
   "id": "a03d96335569a6fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 Searching Experiments\n",
    "\n",
    "[mlflow.client.MlflowClient.search_experiments()](https://mlflow.org/docs/latest/python_api/mlflow.client.html#mlflow.client.MlflowClient.search_experiments)"
   ],
   "id": "b7cb1607e5fd274"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:08.868224Z",
     "start_time": "2025-01-16T03:48:08.845972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)\n",
    "\n",
    "# the output would be a list of Experiment objects"
   ],
   "id": "b451678e7c8115e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Experiment: artifact_location='mlflow-artifacts:/209577529335836473', creation_time=1736946368182, experiment_id='209577529335836473', last_update_time=1736946368182, lifecycle_stage='active', name='Apple_Models1', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
      "                        'experiment contains the produce models for apples.',\n",
      " 'project_name': 'grocery-forecasting',\n",
      " 'project_quarter': 'Q3-2023',\n",
      " 'store_dept': 'produce',\n",
      " 'team': 'stores-ml'}>, <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1736852050555, experiment_id='0', last_update_time=1736852050555, lifecycle_stage='active', name='Default', tags={}>]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To get familiar with accessing elements from returned collections from MLflow APIs, extract the `name` and the `lifecycle_stage` from the `search_experiments()` query and extract these attributes into a dict.",
   "id": "832ba57885603ac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:17.145266Z",
     "start_time": "2025-01-16T03:48:17.141975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "default_experiment = [\n",
    "    {\n",
    "        \"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage\n",
    "    }\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ],
   "id": "60f5091cd062c664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lifecycle_stage': 'active', 'name': 'Default'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Creating experiments",
   "id": "f3fd42dd35865c38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Viewing the MLFlow UI\n",
    "you could see the default experiment with no run data at [http://127.0.0.1:8080](http://127.0.0.1:8080)\n",
    "\n",
    "## Notes on Tags vs Experiments\n",
    "While MLflow does provide a default experiment, it primarily serves as a ‚Äòcatch-all‚Äô safety net for runs initiated without a specified active experiment. However, it‚Äôs not recommended for regular use. Instead, creating unique experiments for specific collections of runs offers numerous advantages, as we‚Äôll explore below.\n",
    "\n",
    "**Benefits of Defining Unique Experiments**:\n",
    "\n",
    "1. **Enhanced Organization**: Experiments allow you to group related runs, making it easier to track and compare them. This is especially helpful when managing numerous runs, as in large-scale projects.\n",
    "2. **Metadata Annotation**: Experiments can carry metadata that aids in organizing and associating runs with larger projects.\n",
    "\n",
    "Consider the scenario below: we‚Äôre simulating participation in a large demand forecasting project. This project involves building forecasting models for various departments in a chain of grocery stores, each housing numerous products. Our focus here is the ‚Äòproduce‚Äô department, which has several distinct items, each requiring its own forecast model. Organizing these models becomes paramount to ensure easy navigation and comparison.\n",
    "\n",
    "**When Should You Define an Experiment?**\n",
    "\n",
    "The guiding principle for creating an experiment is the consistency of the input data. If multiple runs use the same input dataset (even if they utilize different portions of it), they logically belong to the same experiment. For other hierarchical categorizations, using tags is advisable.\n",
    "\n",
    "**[NOTE](https://mlflow.org/docs/latest/getting-started/logging-first-model/step3-create-experiment.html)**\n",
    "\n",
    "While the business product hierarchy in this case doesn‚Äôt explicitly need to be captured within the tags, there is nothing preventing you from doing so. There isn‚Äôt a limit to the number of tags that you can apply. Provided that the keys being used are consistent across experiments and runs to permit search to function properly, any number of arbitrary mappings between tracked models and your specific business rules can be applied.\n"
   ],
   "id": "49a97608f0953044"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 Create the Apples Experiment with Meaningfull Tags",
   "id": "cefaf17795b4b433"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:06:08.191172Z",
     "start_time": "2025-01-15T13:06:08.167491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"This is the grocery forecasting project. \"\n",
    "    \"This experiment contains the produce models for apples.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"grocery-forecasting\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# Create the Experiment, providing a unique name\n",
    "produce_apples_experiment = client.create_experiment(\n",
    "    name=\"Apple_Models1\", tags=experiment_tags\n",
    ")\n"
   ],
   "id": "424e31fcca598da9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Searching Experiments\n",
   "id": "3fee5edcb663eff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.1 Search based on tags",
   "id": "fb4ff51f842f4151"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:22.604176Z",
     "start_time": "2025-01-16T03:48:22.594519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use search_experiments() to search on the project_name tag key\n",
    "\n",
    "apples_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'grocery-forecasting'\"\n",
    ")\n",
    "\n",
    "print((apples_experiment[0])) # this output is an Experiment object not a dict\n",
    "# print(vars(apples_experiment[0])) # this output is a dict\n",
    "# the results are the metadata from the experiment that you created"
   ],
   "id": "d0f9a0c7f6b480d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='mlflow-artifacts:/209577529335836473', creation_time=1736946368182, experiment_id='209577529335836473', last_update_time=1736946368182, lifecycle_stage='active', name='Apple_Models1', tags={'mlflow.note.content': 'This is the grocery forecasting project. This '\n",
      "                        'experiment contains the produce models for apples.',\n",
      " 'project_name': 'grocery-forecasting',\n",
      " 'project_quarter': 'Q3-2023',\n",
      " 'store_dept': 'produce',\n",
      " 'team': 'stores-ml'}>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Create a Dataset about apples",
   "id": "a3b315c259d2b160"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6.1 Defining a dataset generator\n",
   "id": "bc483741ba35ac09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:34.187828Z",
     "start_time": "2025-01-16T03:48:34.180620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def generate_apple_sales_data_with_promo_adjustment(\n",
    "        base_demand: int = 1000, n_rows: int = 5000\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for predicting apple sales demand with seasonality\n",
    "    and inflation.\n",
    "\n",
    "    This function creates a pandas DataFrame with features relevant to apple sales.\n",
    "    The features include date, average_temperature, rainfall, weekend flag, holiday flag,\n",
    "    promotional flag, price_per_kg, and the previous day's demand. The target variable,\n",
    "    'demand', is generated based on a combination of these features with some added noise.\n",
    "\n",
    "    Args:\n",
    "        base_demand (int, optional): Base demand for apples. Defaults to 1000.\n",
    "        n_rows (int, optional): Number of rows (days) of data to generate. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with features and target variable for apple sales prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> df = generate_apple_sales_data_with_seasonality(base_demand=1200, n_rows=6000)\n",
    "        >>> df.head()\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(9999)\n",
    "\n",
    "    # Create date range\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_rows)]\n",
    "    dates.reverse()\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"average_temperature\": np.random.uniform(10, 35, n_rows),\n",
    "            \"rainfall\": np.random.exponential(5, n_rows),\n",
    "            \"weekend\": [(date.weekday() >= 5) * 1 for date in dates],\n",
    "            \"holiday\": np.random.choice([0, 1], n_rows, p=[0.97, 0.03]),\n",
    "            \"price_per_kg\": np.random.uniform(0.5, 3, n_rows),\n",
    "            \"month\": [date.month for date in dates],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Introduce inflation over time (years)\n",
    "    df[\"inflation_multiplier\"] = (\n",
    "            1 + (df[\"date\"].dt.year - df[\"date\"].dt.year.min()) * 0.03\n",
    "    )\n",
    "\n",
    "    # Incorporate seasonality due to apple harvests\n",
    "    df[\"harvest_effect\"] = np.sin(2 * np.pi * (df[\"month\"] - 3) / 12) + np.sin(\n",
    "        2 * np.pi * (df[\"month\"] - 9) / 12\n",
    "    )\n",
    "\n",
    "    # Modify the price_per_kg based on harvest effect\n",
    "    df[\"price_per_kg\"] = df[\"price_per_kg\"] - df[\"harvest_effect\"] * 0.5\n",
    "\n",
    "    # Adjust promo periods to coincide with periods lagging peak harvest by 1 month\n",
    "    peak_months = [4, 10]  # months following the peak availability\n",
    "    df[\"promo\"] = np.where(\n",
    "        df[\"month\"].isin(peak_months),\n",
    "        1,\n",
    "        np.random.choice([0, 1], n_rows, p=[0.85, 0.15]),\n",
    "    )\n",
    "\n",
    "    # Generate target variable based on features\n",
    "    base_price_effect = -df[\"price_per_kg\"] * 50\n",
    "    seasonality_effect = df[\"harvest_effect\"] * 50\n",
    "    promo_effect = df[\"promo\"] * 200\n",
    "\n",
    "    df[\"demand\"] = (\n",
    "                           base_demand\n",
    "                           + base_price_effect\n",
    "                           + seasonality_effect\n",
    "                           + promo_effect\n",
    "                           + df[\"weekend\"] * 300\n",
    "                           + np.random.normal(0, 50, n_rows)\n",
    "                   ) * df[\n",
    "                       \"inflation_multiplier\"\n",
    "                   ]  # adding random noise\n",
    "\n",
    "    # Add previous day's demand\n",
    "    df[\"previous_days_demand\"] = df[\"demand\"].shift(1)\n",
    "    df[\"previous_days_demand\"].fillna(\n",
    "        method=\"bfill\", inplace=True\n",
    "    )  # fill the first row\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df.drop(columns=[\"inflation_multiplier\", \"harvest_effect\", \"month\"], inplace=True)\n",
    "\n",
    "    return df\n"
   ],
   "id": "c54525f3a115a2d1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:35.824606Z",
     "start_time": "2025-01-16T03:48:35.798273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n",
    "\n",
    "data[-20:]"
   ],
   "id": "23a0eec95e5a0d90",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7967/3829094379.py:89: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"previous_days_demand\"].fillna(\n",
      "/tmp/ipykernel_7967/3829094379.py:89: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[\"previous_days_demand\"].fillna(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                          date  average_temperature   rainfall  weekend  \\\n",
       "980 2024-12-28 10:48:35.799340            34.130183   1.454065        1   \n",
       "981 2024-12-29 10:48:35.799339            32.353643   9.462859        1   \n",
       "982 2024-12-30 10:48:35.799338            18.816833   0.391470        0   \n",
       "983 2024-12-31 10:48:35.799337            34.533012   2.120477        0   \n",
       "984 2025-01-01 10:48:35.799336            23.057202   2.365705        0   \n",
       "985 2025-01-02 10:48:35.799335            34.810165   3.089005        0   \n",
       "986 2025-01-03 10:48:35.799334            29.208905   3.673292        0   \n",
       "987 2025-01-04 10:48:35.799334            16.428676   4.077782        1   \n",
       "988 2025-01-05 10:48:35.799333            32.067512   2.734454        1   \n",
       "989 2025-01-06 10:48:35.799332            31.938203  13.883486        0   \n",
       "990 2025-01-07 10:48:35.799331            18.024055   7.544061        0   \n",
       "991 2025-01-08 10:48:35.799330            20.681067  18.820490        0   \n",
       "992 2025-01-09 10:48:35.799330            16.010132   7.705941        0   \n",
       "993 2025-01-10 10:48:35.799329            18.766455   6.274840        0   \n",
       "994 2025-01-11 10:48:35.799328            27.948793  23.705246        1   \n",
       "995 2025-01-12 10:48:35.799327            28.661072  10.329865        1   \n",
       "996 2025-01-13 10:48:35.799326            10.821693   3.575645        0   \n",
       "997 2025-01-14 10:48:35.799325            21.108560   6.221089        0   \n",
       "998 2025-01-15 10:48:35.799323            29.451301   5.021463        0   \n",
       "999 2025-01-16 10:48:35.799316            19.261458   0.438381        0   \n",
       "\n",
       "     holiday  price_per_kg  promo       demand  previous_days_demand  \n",
       "980        0      1.449177      0  1289.802447           1001.085782  \n",
       "981        0      2.856503      0  1136.951553           1289.802447  \n",
       "982        0      1.326429      0   963.352029           1136.951553  \n",
       "983        0      0.970131      0  1039.385504            963.352029  \n",
       "984        0      1.049931      0  1019.486305           1039.385504  \n",
       "985        0      2.035149      0  1002.564672           1019.486305  \n",
       "986        0      2.518098      0  1086.143402           1002.564672  \n",
       "987        0      1.268979      0  1420.207186           1086.143402  \n",
       "988        0      0.762317      0  1396.939894           1420.207186  \n",
       "989        0      1.153301      0   994.409540           1396.939894  \n",
       "990        0      0.610703      0  1078.323183            994.409540  \n",
       "991        0      1.533488      0  1001.499120           1078.323183  \n",
       "992        0      1.632498      1  1221.922141           1001.499120  \n",
       "993        0      2.806554      0   956.412724           1221.922141  \n",
       "994        0      0.829464      0  1417.592622            956.412724  \n",
       "995        0      2.290591      0  1263.465043           1417.592622  \n",
       "996        0      0.897473      0  1016.336362           1263.465043  \n",
       "997        0      1.093864      0  1063.698477           1016.336362  \n",
       "998        0      2.493085      0   979.255235           1063.698477  \n",
       "999        0      2.610422      0   880.188828            979.255235  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>price_per_kg</th>\n",
       "      <th>promo</th>\n",
       "      <th>demand</th>\n",
       "      <th>previous_days_demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2024-12-28 10:48:35.799340</td>\n",
       "      <td>34.130183</td>\n",
       "      <td>1.454065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.449177</td>\n",
       "      <td>0</td>\n",
       "      <td>1289.802447</td>\n",
       "      <td>1001.085782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2024-12-29 10:48:35.799339</td>\n",
       "      <td>32.353643</td>\n",
       "      <td>9.462859</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.856503</td>\n",
       "      <td>0</td>\n",
       "      <td>1136.951553</td>\n",
       "      <td>1289.802447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2024-12-30 10:48:35.799338</td>\n",
       "      <td>18.816833</td>\n",
       "      <td>0.391470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.326429</td>\n",
       "      <td>0</td>\n",
       "      <td>963.352029</td>\n",
       "      <td>1136.951553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2024-12-31 10:48:35.799337</td>\n",
       "      <td>34.533012</td>\n",
       "      <td>2.120477</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>0</td>\n",
       "      <td>1039.385504</td>\n",
       "      <td>963.352029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2025-01-01 10:48:35.799336</td>\n",
       "      <td>23.057202</td>\n",
       "      <td>2.365705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.049931</td>\n",
       "      <td>0</td>\n",
       "      <td>1019.486305</td>\n",
       "      <td>1039.385504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2025-01-02 10:48:35.799335</td>\n",
       "      <td>34.810165</td>\n",
       "      <td>3.089005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.035149</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.564672</td>\n",
       "      <td>1019.486305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2025-01-03 10:48:35.799334</td>\n",
       "      <td>29.208905</td>\n",
       "      <td>3.673292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.518098</td>\n",
       "      <td>0</td>\n",
       "      <td>1086.143402</td>\n",
       "      <td>1002.564672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2025-01-04 10:48:35.799334</td>\n",
       "      <td>16.428676</td>\n",
       "      <td>4.077782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.268979</td>\n",
       "      <td>0</td>\n",
       "      <td>1420.207186</td>\n",
       "      <td>1086.143402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2025-01-05 10:48:35.799333</td>\n",
       "      <td>32.067512</td>\n",
       "      <td>2.734454</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762317</td>\n",
       "      <td>0</td>\n",
       "      <td>1396.939894</td>\n",
       "      <td>1420.207186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2025-01-06 10:48:35.799332</td>\n",
       "      <td>31.938203</td>\n",
       "      <td>13.883486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.153301</td>\n",
       "      <td>0</td>\n",
       "      <td>994.409540</td>\n",
       "      <td>1396.939894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2025-01-07 10:48:35.799331</td>\n",
       "      <td>18.024055</td>\n",
       "      <td>7.544061</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.610703</td>\n",
       "      <td>0</td>\n",
       "      <td>1078.323183</td>\n",
       "      <td>994.409540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2025-01-08 10:48:35.799330</td>\n",
       "      <td>20.681067</td>\n",
       "      <td>18.820490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533488</td>\n",
       "      <td>0</td>\n",
       "      <td>1001.499120</td>\n",
       "      <td>1078.323183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2025-01-09 10:48:35.799330</td>\n",
       "      <td>16.010132</td>\n",
       "      <td>7.705941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.632498</td>\n",
       "      <td>1</td>\n",
       "      <td>1221.922141</td>\n",
       "      <td>1001.499120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2025-01-10 10:48:35.799329</td>\n",
       "      <td>18.766455</td>\n",
       "      <td>6.274840</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.806554</td>\n",
       "      <td>0</td>\n",
       "      <td>956.412724</td>\n",
       "      <td>1221.922141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2025-01-11 10:48:35.799328</td>\n",
       "      <td>27.948793</td>\n",
       "      <td>23.705246</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0</td>\n",
       "      <td>1417.592622</td>\n",
       "      <td>956.412724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2025-01-12 10:48:35.799327</td>\n",
       "      <td>28.661072</td>\n",
       "      <td>10.329865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.290591</td>\n",
       "      <td>0</td>\n",
       "      <td>1263.465043</td>\n",
       "      <td>1417.592622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2025-01-13 10:48:35.799326</td>\n",
       "      <td>10.821693</td>\n",
       "      <td>3.575645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897473</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.336362</td>\n",
       "      <td>1263.465043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2025-01-14 10:48:35.799325</td>\n",
       "      <td>21.108560</td>\n",
       "      <td>6.221089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.093864</td>\n",
       "      <td>0</td>\n",
       "      <td>1063.698477</td>\n",
       "      <td>1016.336362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2025-01-15 10:48:35.799323</td>\n",
       "      <td>29.451301</td>\n",
       "      <td>5.021463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.493085</td>\n",
       "      <td>0</td>\n",
       "      <td>979.255235</td>\n",
       "      <td>1063.698477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2025-01-16 10:48:35.799316</td>\n",
       "      <td>19.261458</td>\n",
       "      <td>0.438381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.610422</td>\n",
       "      <td>0</td>\n",
       "      <td>880.188828</td>\n",
       "      <td>979.255235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7. Logging our first runs with MLflow\n",
    "\n",
    "Core features of MLflow Tracking:\n",
    "- Making use of the start_run context for creating and efficiently managing runs.\n",
    "- An introduction to logging, covering tags, parameters, and metrics.\n",
    "- Understanding the role and formation of a model signature.\n",
    "- Logging a trained model, solidifying its presence in our MLflow run.\n"
   ],
   "id": "c2447890e0d0301b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7.1 Using MLflow Tracking to keep track of training",
   "id": "afb5b84fae4cc47f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:41.369300Z",
     "start_time": "2025-01-16T03:48:41.366638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ],
   "id": "3f486600f147d1b9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the global reference to the Tracking server‚Äôs address.",
   "id": "54da7a07e7648157"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T03:48:43.183487Z",
     "start_time": "2025-01-16T03:48:43.181098Z"
    }
   },
   "cell_type": "code",
   "source": "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")",
   "id": "debe24479a437a2d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Defining an Experiment that will be used to log runs to.",
   "id": "7a837ddfbf1e7e2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T04:43:56.577776Z",
     "start_time": "2025-01-16T04:43:56.569041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sets the current active experiment to the \"Apple_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"Apple_Models1\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"apples_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"rf_apples\"\n"
   ],
   "id": "37722ce38ca22581",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Run the experiment",
   "id": "de0a88875a7a43ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T04:44:02.420654Z",
     "start_time": "2025-01-16T04:43:59.264872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into features and target and drop irrelevant date field and target field\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf, input_example=X_val, artifact_path=artifact_path\n",
    "\n",
    "    )\n"
   ],
   "id": "d386ced4b52462b6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diyrad167/.conda/envs/LearnMLOps/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run apples_rf_test at: http://127.0.0.1:8080/#/experiments/209577529335836473/runs/e614276845c647deaa4c6f7a0224ad4c\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/209577529335836473\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Horayy you've just logged your first MLflow model!! How about let's try another one in the same Experiment which is `Apple_Models1`",
   "id": "995ca16526559946"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Defining the experiment",
   "id": "e3a5dce1ea2d1264"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T06:02:36.355877Z",
     "start_time": "2025-01-16T06:02:36.345773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sets the current active experiment\n",
    "apple_experiment_v2 = mlflow.set_experiment(\"Apple_Models1\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "run_name2 = \"apple_dtr_test\"\n",
    "\n",
    "# Define the artifact path that the model will save to\n",
    "artifact_path2 = \"dtr_apples\""
   ],
   "id": "2cf94b326bfe2bc0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T06:09:04.751665Z",
     "start_time": "2025-01-16T06:09:02.286010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr_params = {\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"splitter\": \"random\",\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "dtr = DecisionTreeRegressor(**dtr_params)\n",
    "\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtr.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "metrics2 = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name2) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(dtr_params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics2)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=dtr, input_example=X_val, artifact_path=artifact_path2\n",
    "    )"
   ],
   "id": "3cdb0da590eb11c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diyrad167/.conda/envs/LearnMLOps/lib/python3.10/site-packages/mlflow/types/utils.py:435: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run apple_dtr_test at: http://127.0.0.1:8080/#/experiments/209577529335836473/runs/81f250f1838f49ce9257de8757d8897c\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/209577529335836473\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Congrats!! you've just logged another MLflow model, hope this notebook understanable for you to take your first step into MLOps using MLflow ^-^",
   "id": "a38bbfb83924aea4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
